# -*- coding: utf-8 -*-
"""CarDamageDetection-SeverityPrediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/rajendrawarke/CarDamageDetection-SeverityPrediction/blob/main/CarDamageDetection-SeverityPrediction.ipynb
"""

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/rajendrawarke/CarDamageDetection-SeverityPrediction.git
# %cd CarDamageDetection-SeverityPrediction

!pip install -q ultralytics==8.0.210
!pip install -q roboflow
!pip install tensorflow==2.19.0
!pip install -q opencv-python-headless matplotlib seaborn scikit-learn pandas imgaug
!pip install -q scikit-learn

import tensorflow as tf
import matplotlib
import seaborn as sns
import numpy as np
import ultralytics
from ultralytics import YOLO
import roboflow
import sklearn
import cv2
import os, glob, pprint
from pathlib import Path
import matplotlib.pyplot as plt

print('tensorflow : ',tf.__version__)
print('matplotlib : ',matplotlib.__version__)
print('sns : ',sns.__version__)
print('np : ',np.__version__)
print('sklearn : ',sklearn.__version__)
print('ultralytics : ',ultralytics.__version__)
print('roboflow : ',roboflow.__version__)
print('cv2 : ',cv2.__version__)

pprint.pprint(sorted(glob.glob("data/**", recursive=True))[:5])

## As data.yaml file is already defined in the roboflow dataset, we will not execute below code to create our own yaml file for training the yolo model
# data_yaml = """
# train: dataset/train/images
# val: dataset/valid/images
# nc: 3
# names: ['scratch','dent','glass_shatter']
# """
# with open("data.yaml","w") as f:
#     f.write(data_yaml.strip())
# print("Wrote data.yaml")

import torch
def unsafe_torch_load(*args, **kwargs):
    kwargs['weights_only'] = False
    return torch.serialization.orig_load(*args, **kwargs)

if not hasattr(torch.serialization, 'orig_load'):
    torch.serialization.orig_load = torch.load
    torch.load = unsafe_torch_load

model = YOLO("yolov8n.pt")
model.train(data="datasets/data.yaml", epochs=15, imgsz=640, batch=8, name="car_damage_yolov8n")

# api keyfor wandb login : f08db23a1f25a5634bb41c3cf875470469d26c46

results = model.predict(source="datasets/valid/images", show=True)

metrics = model.val()

detector_path = "runs/detect/car_damage_yolov8n/weights/best.pt"
detector = YOLO(detector_path)

os.makedirs("crops", exist_ok=True)
val_images = sorted(list(Path("datasets/valid/images").glob("*.*")))
crop_count = 0

for img_path in val_images:
    res = detector.predict(source=str(img_path), imgsz=640, conf=0.25, verbose=False)
    r = res[0]
    img = cv2.imread(str(img_path))
    h,w = img.shape[:2]
    for i,box in enumerate(r.boxes):
        xyxy = box.xyxy[0].cpu().numpy()  # [x1,y1,x2,y2]
        conf = float(box.conf[0].cpu().numpy())
        cls = int(box.cls[0].cpu().numpy())
        x1,y1,x2,y2 = map(int, xyxy)
        pad = 8
        x1, y1 = max(0,x1-pad), max(0,y1-pad)
        x2, y2 = min(w-1,x2+pad), min(h-1,y2+pad)
        crop = img[y1:y2, x1:x2]
        fname = f"crops/{img_path.stem}_box{i}_cls{cls}_conf{int(conf*100)}.jpg"
        cv2.imwrite(fname, crop)
        crop_count += 1

print(f"Saved {crop_count} crops to crops/")

!zip -r yolo_evaluation.zip runs/detect/car_damage_yolov8n2

!zip -r crops.zip crops/

!zip -r runs.zip runs/

# Create severity dataset
# image path,severity

!unzip crops.zip

import pandas as pd
from sklearn.model_selection import train_test_split

csv_file_path = 'severity_labels.csv'
data = pd.read_csv(csv_file_path)

image_folder_path = 'crops/'

train_df, val_df = train_test_split(data, test_size=0.2, random_state=42, stratify=data['label'])

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_dataframe(
    dataframe=train_df,
    x_col='image path',
    y_col='label',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

val_generator = val_datagen.flow_from_dataframe(
    dataframe=val_df,
    x_col='image path',
    y_col='label',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

from sklearn.utils import class_weight
class_labels = data['label'].values
class_weights = class_weight.compute_class_weight(
    class_weight='balanced',
    classes=np.unique(class_labels),
    y=class_labels
)
class_weight_dict = dict(enumerate(class_weights))
print("Class weights:", class_weight_dict)

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint

# Define the number of classes
num_classes = 3

# Load the EfficientNetB0 base model
base = EfficientNetB0(include_top=False, input_shape=(224, 224, 3), weights='imagenet')
base.trainable = False  # Freeze the base layers

# Define the model architecture
inputs = layers.Input(shape=(224, 224, 3))
x = base(inputs, training=False)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.3)(x)
x = layers.Dense(256, activation='relu')(x)
x = layers.Dropout(0.2)(x)
outputs = layers.Dense(num_classes, activation='softmax')(x)
model = models.Model(inputs, outputs)

# Compile the model
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
              loss='categorical_crossentropy',  # Use 'categorical_crossentropy' if labels are one-hot encoded
              metrics=['accuracy'])
model.summary()

# Set up callbacks for training
callbacks = [
    ModelCheckpoint("best_severity_model.h5", monitor='val_accuracy', save_best_only=True, mode='max'),
    EarlyStopping(monitor='val_accuracy', patience=6, restore_best_weights=True),
    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)
]

# Fit the model using the data generators
history = model.fit(train_generator,
                    validation_data=val_generator,
                    epochs=15,
                    callbacks=callbacks)
                    # class_weight=class_weight_dict)

val_loss, val_acc = model.evaluate(val_generator)
print("Val loss:", val_loss, "Val acc:", val_acc)

y_pred_prob = model.predict(val_generator)
y_true=val_generator.classes
y_pred=np.argmax(y_pred_prob,axis=1)

from sklearn.metrics import classification_report, confusion_matrix
print(classification_report(y_true, y_pred, target_names=['minor','moderate','severe']))
print(confusion_matrix(y_true, y_pred))

import numpy as np
from PIL import Image, ImageDraw, ImageFont

from ultralytics import YOLO
detector = YOLO("best.pt")
severity_model = tf.keras.models.load_model("best_severity_model.h5")

def infer_and_visualize(img_path, conf_thresh=0.25):
    img = cv2.imread(img_path)
    h,w = img.shape[:2]
    res = detector.predict(source=str(img_path), imgsz=640, conf=conf_thresh, verbose=False)
    r = res[0]
    pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(pil)
    for box in r.boxes:
        xyxy = box.xyxy[0].cpu().numpy().astype(int)
        conf = float(box.conf[0].cpu().numpy())
        cls = int(box.cls[0].cpu().numpy())
        x1,y1,x2,y2 = xyxy
        pad = 8
        x1, y1 = max(0,x1-pad), max(0,y1-pad)
        x2, y2 = min(w-1,x2+pad), min(h-1,y2+pad)
        crop = img[y1:y2, x1:x2]
        crop_resized = cv2.resize(crop, (224,224))/255.0
        pred = severity_model.predict(np.expand_dims(crop_resized, 0))
        severity = ['minor','moderate','severe'][int(np.argmax(pred))]
        draw.rectangle([x1,y1,x2,y2], outline="red", width=3)
        draw.text((x1, max(0,y1-18)), f"{severity} {conf:.2f}", fill="yellow")
    display(pil)

infer_and_visualize("dataset/valid/images/example.jpg", conf_thresh=0.3)